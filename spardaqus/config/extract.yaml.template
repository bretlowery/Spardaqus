spardaqus:
  extract:
    endpoint: splunk
    transport: kafka
  splunk:
    host: <hostname>
    port: <port>
    username: <splunk-username>
    password: <splunk-password>
    index: <indexname>>
    host_filter: none
    source_filter: none
    sourcetype_filter: none
    query_filter: none
    query_timeout: 30
    sample_percentage: 100
    scheme: https
    batch_goal: 100000  # must be <= Splunk's maxresultrows setting (located in $SPLUNK_HOME/etc/system/default/limits.conf), which will be used instead if batch_goal's value here exceeds it.
    max_connection_attempts: 6
    connection_retry_interval: 10
    timestamp_field_name: none
    timestamp_field_format: "%d/%b/%Y:%H:%M:%S %z"
    forward: true
    earliest: "2019-01-01 00:00:00"
    latest: none
    error_statuses: FATAL,ERROR
    warning_statuses: WARN,WARNING
    on_no_results: wait
    on_no_results_wait_interval: 60
    enable_query_comment: true
    query_comment: If enabled, this is prefixed to every Splunk query issued
  kafka:
    bootstrap.servers: <hostname>:<port>
    group.id: <group-id>
    topic: default
    producer.options: {'auto.offset.reset': 'earliest',
                       'message.timeout.ms': 30000,
                       'request.timeout.ms': 30000,
                       'socket.timeout.ms': 29990,
                        # 'security.protocol': 'ssl',
                        # 'ssl.ca.location': 'ca-cert',
                        # 'ssl.certificate.location': 'cert-signed',
                        # 'ssl.key.location': 'ca-key',
                        # 'ssl.key.password': 'test1234'
      }
    threads: 1
    idempotence: true
    losstolerance: zero
    maxwait: 300
